---
version: "3"

x-task-vars: &task-vars
  app: '{{.app}}'
  controller: '{{.controller}}'
  namespace: '{{.namespace}}'
  claim: '{{.claim}}'
  ts: '{{.ts}}'
  kustomization: '{{.kustomization}}'
  previous: '{{.previous}}'

vars:
  destinationTemplate: "{{.ROOT_DIR}}/.taskfiles/VolSync/ReplicationDestination.tmpl.yaml"
  wipeJobTemplate: "{{.ROOT_DIR}}/.taskfiles/VolSync/WipeJob.tmpl.yaml"
  waitForJobScript: "{{.ROOT_DIR}}/.taskfiles/VolSync/wait-for-job.sh"
  listJobTemplate: "{{.ROOT_DIR}}/.taskfiles/VolSync/ListJob.tmpl.yaml"
  unlockJobTemplate: "{{.ROOT_DIR}}/.taskfiles/VolSync/UnlockJob.tmpl.yaml"
  ts: '{{now | date "150405"}}'

tasks:

  list:
    desc: List all snapshots taken by restic for a given ReplicationSource (ex. task volsync:list app=plex [namespace=default])
    silent: true
    cmds:
      - envsubst < <(cat {{.listJobTemplate}}) | kubectl apply -f -
      - bash {{.waitForJobScript}} list-{{.app}}-{{.ts}} {{.namespace}}
      - kubectl -n {{.namespace}} wait job/list-{{.app}}-{{.ts}} --for condition=complete --timeout=1m
      - kubectl -n {{.namespace}} logs job/list-{{.app}}-{{.ts}} --container list
      - kubectl -n {{.namespace}} delete job list-{{.app}}-{{.ts}}
    vars:
      app: '{{ or .app (fail "ReplicationSource `app` is required") }}'
      namespace: '{{.namespace | default "default"}}'
    env: *task-vars
    preconditions:
      - sh: test -f {{.waitForJobScript}}
      - sh: test -f {{.listJobTemplate}}

  unlock:
    desc: Unlocks restic repository for a given ReplicationSource (ex. task volsync:unlock app=plex [namespace=default])
    silent: true
    cmds:
      - envsubst < <(cat {{.unlockJobTemplate}}) | kubectl apply -f -
      - bash {{.waitForJobScript}} unlock-{{.app}}-{{.ts}} {{.namespace}}
      - kubectl -n {{.namespace}} wait job/unlock-{{.app}}-{{.ts}} --for condition=complete --timeout=1m
      - kubectl -n {{.namespace}} logs job/unlock-{{.app}}-{{.ts}} --container unlock
      - kubectl -n {{.namespace}} delete job unlock-{{.app}}-{{.ts}}
    vars:
      app: '{{ or .app (fail "ReplicationSource `app` is required") }}'
      namespace: '{{.namespace | default "default"}}'
    env: *task-vars
    preconditions:
      - sh: test -f {{.waitForJobScript}}
      - sh: test -f {{.unlockJobTemplate}}

  # To run backup jobs in parallel for all replicationsources:
  #  - kubectl get replicationsources --all-namespaces --no-headers | awk '{print $2, $1}' | xargs --max-procs=4 -l bash -c 'task volsync:snapshot app=$0 namespace=$1'
  #
  snapshot:
    desc: Trigger a Restic ReplicationSource snapshot (ex. task volsync:snapshot app=plex [namespace=default])
    cmds:
      - kubectl -n {{.namespace}} patch replicationsources {{.app}} --type merge -p '{"spec":{"trigger":{"manual":"{{.ts}}"}}}'
      - bash {{.waitForJobScript}} volsync-src-{{.app}} {{.namespace}}
      - kubectl -n {{.namespace}} wait job/volsync-src-{{.app}} --for condition=complete --timeout=120m
      # TODO: Find a way to output logs
      # Error from server (NotFound): jobs.batch "volsync-src-zzztest" not found
      # - kubectl -n {{.namespace}} logs job/volsync-src-{{.app}}
    vars:
      app: '{{ or .app (fail "ReplicationSource `app` is required") }}'
      namespace: '{{.namespace | default "default"}}'
    env: *task-vars
    preconditions:
      - sh: test -f {{.waitForJobScript}}
      - sh: kubectl -n {{.namespace}} get replicationsources {{.app}}
        msg: "ReplicationSource '{{.app}}' not found in namespace '{{.namespace}}'"

  # To run restore jobs in parallel for all replicationdestinations:
  #   - kubectl get replicationsources --all-namespaces --no-headers | awk '{print $2, $1}' | xargs --max-procs=2 -l bash -c 'task volsync:restore app=$0 namespace=$1'
  #
  restore:
    desc: Trigger a Restic ReplicationSource restore (ex. task volsync:restore app=plex [namespace=default])
    cmds:
      - task: restore-suspend-app
        vars: *task-vars
      - task: restore-wipe-job
        vars: *task-vars
      - task: restore-volsync-job
        vars: *task-vars
      - task: restore-resume-app
        vars: *task-vars
    vars:
      app: '{{ or .app (fail "Variable `app` is required") }}'
      namespace: '{{.namespace | default "default"}}'
      # 1) Query to find the Flux Kustomization associated with the ReplicationSource (app)
      kustomization:
        sh: |
          kubectl -n {{.namespace}} get replicationsource {{.app}} \
            -o jsonpath="{.metadata.labels.kustomize\.toolkit\.fluxcd\.io/name}"
      # 2) Query to find the Claim associated with the ReplicationSource (app)
      claim:
        sh: |
          kubectl -n {{.namespace}} get replicationsource {{.app}} \
            -o jsonpath="{.spec.sourcePVC}"
      # 3) Query to find the controller associated with the PersistentVolumeClaim (claim)
      controller:
        sh: |
          app=$(kubectl -n {{.namespace}} get persistentvolumeclaim {{.claim}} -o jsonpath="{.metadata.labels.app\.kubernetes\.io/name}")
          if kubectl -n {{ .namespace }} get deployment.apps/$app >/dev/null 2>&1 ; then
            echo "deployment.apps/$app"
          else
            echo "statefulset.apps/$app"
          fi
      previous: "{{.previous | default 2}}"
    env: *task-vars
    preconditions:
      - sh: test -f {{.wipeJobTemplate}}
      - sh: test -f {{.destinationTemplate}}
      - sh: test -f {{.waitForJobScript}}

  # Suspend the Flux ks and hr
  restore-suspend-app:
    internal: true
    cmds:
      - flux -n flux-system suspend kustomization {{.kustomization}}
      - flux -n {{.namespace}} suspend helmrelease {{.app}}
      - kubectl -n {{.namespace}} scale {{.controller}} --replicas 0
      - kubectl -n {{.namespace}} wait pod --for delete --selector="app.kubernetes.io/name={{.app}}" --timeout=2m
    env: *task-vars

  # Wipe the PVC of all data
  restore-wipe-job:
    internal: true
    cmds:
      - envsubst < <(cat {{.wipeJobTemplate}}) | kubectl apply -f -
      - bash {{.waitForJobScript}} wipe-{{.app}}-{{.claim}}-{{.ts}} {{.namespace}}
      - kubectl -n {{.namespace}} wait job/wipe-{{.app}}-{{.claim}}-{{.ts}} --for condition=complete --timeout=120m
      - kubectl -n {{.namespace}} logs job/wipe-{{.app}}-{{.claim}}-{{.ts}} --container wipe
      - kubectl -n {{.namespace}} delete job wipe-{{.app}}-{{.claim}}-{{.ts}}
    env: *task-vars

  # Create VolSync replicationdestination CR to restore data
  restore-volsync-job:
    internal: true
    cmds:
      - envsubst < <(cat {{.destinationTemplate}}) | kubectl apply -f -
      - bash {{.waitForJobScript}} volsync-dst-{{.app}}-{{.claim}}-{{.ts}} {{.namespace}}
      - kubectl -n {{.namespace}} wait job/volsync-dst-{{.app}}-{{.claim}}-{{.ts}} --for condition=complete --timeout=120m
      - kubectl -n {{.namespace}} delete replicationdestination {{.app}}-{{.claim}}-{{.ts}}
    env: *task-vars

  # Resume Flux ks and hr
  restore-resume-app:
    internal: true
    cmds:
      - flux -n {{.namespace}} resume helmrelease {{.app}}
      - flux -n flux-system resume kustomization {{.kustomization}}
    env: *task-vars
