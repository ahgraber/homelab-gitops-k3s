---
apiVersion: v1
kind: ConfigMap
metadata:
  name: values-alertmanager
  namespace: monitoring
data:
  values.yaml: |
    ## ref: https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml
    ## ref: https://github.com/prometheus-community/helm-charts/blob/main/charts/alertmanager/values.yaml
    alertmanager:
      enabled: true

      nameOverride: alertmanager

      ingress:
        enabled: false

      alertmanagerSpec:
        externalUrl: alertmanager.${SECRET_DOMAIN}
        retention: 72h
        storage:
          volumeClaimTemplate:
            spec:
              storageClassName: local-path # csi-truenas-iscsi
              resources:
                requests:
                  storage: 1Gi
              ## for attaching retained PV
              # selector:
              #   matchLabels:
              #     app.kubernetes.io/name: alertmanager
              #     app.kubernetes.io/instance: kps-alertmanager
        resources:
          requests:
            cpu: 11m
            memory: 53M
          limits:
            cpu: 11m
            memory: 53M

        tolerations: []
        nodeSelector: {}

      ## ref: https://prometheus.io/docs/alerting/alertmanager/
      config:
        global:
          resolve_timeout: 5m
        receivers:
          - name: "null"
          - name: "email"
            email_configs:
              - to: "${SECRET_DEFAULT_EMAIL}"
                from: "${SECRET_SMTP_ADDRESS}"
                smarthost: in-v3.mailjet.com:587
                auth_username: "${SECRET_SMTP_USER}"
                auth_password: "${SECRET_SMTP_PWD}"
                # auth_identity: "${SECRET_SMTP_ADDRESS}"
                # auth_secret: "${SECRET_SMTP_PWD}"
                require_tls: true
                # prettier-ignore
                text: >-
                  [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ if ne .CommonAnnotations.summary ""}}{{ .CommonAnnotations.summary }} {{ else if ne .CommonAnnotations.message ""}}{{ .CommonAnnotations.message }} {{ else if ne .CommonAnnotations.description ""}}{{ .CommonAnnotations.description }} {{ else }}{{ .CommonLabels.alertname }}{{ end }}

                  {{ range .Alerts -}}
                    *Alert:* {{ .Annotations.title }}{{ if .Labels.severity }} - `{{ .Labels.severity }}`{{ end }}
                  {{ if ne .Annotations.summary ""}}*Summary:* {{ .Annotations.summary }} {{ else if ne .Annotations.message ""}}*Message:* {{ .Annotations.message }} {{ else if ne .Annotations.description ""}}*Description:* {{ .Annotations.description }}{{ end }}
                  *Details:*
                    {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* `{{ .Value }}`
                    {{ end }}
                  {{ end }}

        route:
          group_by: ["alertname", "job"]
          group_wait: 30s
          group_interval: 5m
          repeat_interval: 6h
          receiver: "email"
          routes:
            - receiver: "null"
              match:
                alertname: InfoInhibitor
            - receiver: "null"
              match:
                alertname: Watchdog
            # - receiver: "null"
            #   match:
            #     alertname: etcdHighNumberOfFailedGRPCRequests
            - receiver: "email"
              match_re:
                # severity: critical|warning
                severity: critical
              continue: true

        # Inhibition rules allow to mute a set of alerts given that another alert is firing.
        # We use this to mute any warning-level notifications if the same alert is already critical.
        inhibit_rules:
          - source_match:
              severity: "critical"
            target_match:
              severity: "warning"
            equal: ["alertname", "namespace"]
