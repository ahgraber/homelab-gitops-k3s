---
# yaml-language-server: $schema=https://kubernetes-schemas.pages.dev/helm.toolkit.fluxcd.io/helmrelease_v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app crowdsec
spec:
  chart:
    spec:
      chart: crowdsec
      version: 0.17.1
      sourceRef:
        kind: HelmRepository
        name: crowdsec
        namespace: flux-system
  interval: 15m
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      strategy: rollback
      retries: 3
  driftDetection:
    mode: enabled
    ignore:
      - paths:
          - /spec/containers/resources/limits
        target:
          kind: Pod
  values:
    # -- for raw logs format: json or cri (docker|containerd)
    container_runtime: containerd

    image:
      # -- docker image repository name
      repository: ghcr.io/crowdsecurity/crowdsec
      tag: v1.6.4@sha256:091229068a9dab7f8c1ae41086669620da2980c6ccc26f9e358a75aaa7cb4a27
      # -- pullPolicy
      pullPolicy: IfNotPresent
      # -- docker image tag

    config:
      # -- General configuration (https://docs.crowdsec.net/docs/configuration/crowdsec_configuration/#configuration-example)
      config.yaml.local: |
        api:
          server:
            auto_registration: # Activate if not using TLS for authentication
              enabled: true
              token: "${REGISTRATION_TOKEN}" # /!\ Do not modify this variable (auto-generated and handled by the chart)
              allowed_ranges: # /!\ Make sure to adapt to the pod IP ranges used by your cluster
                - "127.0.0.1/32"
                - "192.168.0.0/16"
                - "10.0.0.0/8"
                - "172.16.0.0/12"
        db_config:
          flush:
            agents_autodelete:
              cert: 60m # This is TLS client authentication
              login_password: 60m # This includes the auto registration token as well
            ## Flush both login types if the machine has not logged in for 60 minutes or more
    # # If you want to specify secrets that will be used for all your crowdsec-agents
    # # secrets can be provided be env variables
    # secrets:
    #   # -- agent username (default is generated randomly)
    #   username: ""
    #   # -- agent password (default is generated randomly)
    #   password: ""

    # lapi (local api) will deploy pod with crowdsec lapi and dashboard as deployment
    lapi:
      env:
        - name: TZ
          value: ${TIMEZONE}
        ### by default disable the agent for local API pods --> this is set in lapi-deployment helm template
        # - name: DISABLE_AGENT
        #   value: "true"
        # # If it's a test, we don't want to share signals with CrowdSec so disable the Online API.
        # - name: DISABLE_ONLINE_API
        #   value: "true"
        - name: ENROLL_KEY
          valueFrom:
            secretKeyRef:
              name: *app
              key: ENROLL_KEY
        - name: ENROLL_INSTANCE_NAME
          value: k8s_cluster
        - name: ENROLL_TAGS
          value: "k8s linux"
        - name: BOUNCER_KEY_INGRESS
          valueFrom:
            secretKeyRef:
              name: *app
              key: BOUNCER_KEY_INGRESS
      # secrets:
      #   # -- Shared LAPI secret. Will be generated randomly if not specified. Size must be > 64 characters
      #   csLapiSecret: ""
      #   # -- Registration Token for Appsec. Will be generated randomly if not specified. Size must be > 48 characters
      #   registrationToken: ""

      dashboard:
        enabled: false

      resources:
        requests:
          cpu: 150m
          memory: 100M
        limits:
          memory: 100M

      # -- Enable persistent volumes
      persistentVolume:
        # -- Persistent volume for data folder. Stores e.g. registered bouncer api keys
        data:
          enabled: true
          accessModes:
            - ReadWriteMany
          storageClassName: ceph-fs
          size: 1Gi
        # -- Persistent volume for config folder. Stores e.g. online api credentials
        config:
          enabled: true
          accessModes:
            - ReadWriteMany
          storageClassName: ceph-fs
          size: 100Mi

      nodeSelector:
        node-role.kubernetes.io/control-plane: "true"
      tolerations:
        - key: node-role.kubernetes.io/control-plane
          operator: Exists

      # -- Enable service monitoring (exposes "metrics" port "6060" for Prometheus)
      metrics:
        enabled: true
        serviceMonitor:
          enabled: true

    # agent will deploy pod on every node as daemonSet to read wanted pods logs
    agent:
      lapiURL: ""
      # -- lapiHost for agent to connect to (default is the lapi service)
      lapiHost: ""
      # -- lapiPort for agent to connect to (default is the lapi service port)
      lapiPort: 8080
      acquisition:
        # -- Specify each pod you want to process it logs (namespace, podName and program)
        - namespace: networking
          podName: nginx-internal-controller-*
          program: nginx
        - namespace: networking
          podName: nginx-external-controller-*
          program: nginx
        # - namespace: cluster-system
        #   podName: keycloak-postgresql-*
        #   program: pgsql
      resources:
        limits:
          memory: 100Mi
        requests:
          cpu: 150m
          memory: 100Mi
      # -- Enable persistent volumes
      persistentVolume:
        # -- Persistent volume for config folder. Stores local config (parsers, scenarios etc.)
        config:
          enabled: true
          accessModes:
            - ReadWriteMany
          storageClassName: ceph-fs
          size: 100Mi
      # -- environment variables from crowdsecurity/crowdsec docker image
      env:
        - name: TZ
          value: ${TIMEZONE}
        # # default disable local API on the agent pod --> this is set in agent-daemonset helm template
        # - name: DISABLE_ONLINE_API
        #   value: "false"
        # - name: LEVEL_TRACE
        #   value: "false"
        # - name: LEVEL_DEBUG
        #   value: "false"
        # - name: LEVEL_INFO
        #   value: "false"

        ### "Parsers and Scenarios must be present on the agents. It's not useful to deploy them on LAPI"
        # COLLECTIONS are bundles of PARSERS and SCENARIOS
        - name: COLLECTIONS
          value: >-
            crowdsecurity/linux
            crowdsecurity/sshd
            crowdsecurity/nginx
            crowdsecurity/base-http-scenarios
            crowdsecurity/http-cve
            crowdsecurity/pgsql

        - name: PARSERS
          # https://hub.crowdsec.net/author/crowdsecurity/configurations/cri-logs
          # https://hub.crowdsec.net/author/crowdsecurity/configurations/docker-logs
          value: >-
            crowdsecurity/cri-logs
            crowdsecurity/docker-logs

        # - name: SCENARIOS
        #   value: |
      # -- tolerations for agent
      tolerations:
        - key: node-role.kubernetes.io/control-plane
          operator: Exists

      # -- Enable service monitoring (exposes "metrics" port "6060" for Prometheus)
      metrics:
        enabled: true
        serviceMonitor:
          enabled: true

    # -- Enable AppSec (https://docs.crowdsec.net/docs/next/appsec/intro)
    appsec:
      enabled: false
